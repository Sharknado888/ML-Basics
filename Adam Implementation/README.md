# Implementation of Adam Optimization algorithm from scratch
<br>
<br>
![Adam locus early stopping](https://user-images.githubusercontent.com/44333704/121627492-10756900-ca95-11eb-8535-54a0362cd35c.JPG)


## References

1. Adam: A Method for Stochastic Optimization, Diederik P. Kingma, Jimmy Ba, 2017
2. An overview of gradient descent optimization algorithms (https://ruder.io/optimizing-gradient-descent/index.html), 2016.
